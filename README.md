# Finetuned_Llama2

As part of an independent research initiative, I undertook a project to improve the performance of a large language model, Meta LLAMA2, 
which boasts an impressive 7 billion parameters. The goal was to enhance its capabilities in answering questions and comprehending context by 
leveraging the Stanford Question Answering Dataset (SQuAD).

By successfully finetuning the Meta LLAMA2 language model on the SQuAD dataset, I demonstrated my ability to contribute to the advancement
of natural language processing technologies. The improved model exhibited enhanced performance in question-answering tasks and showcased 
its potential for real-world applications, such as chatbots, virtual assistants, and search engines.
Finally, pusheed the model to Hugging Face. Feel free to try out the model available on Hugging Face: suchetajjw47/fine_tuned_llama2-squad
